{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3a467aa071e54d858887a056c44379c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1d8f29410044465182058cb91da32b46","IPY_MODEL_da665aeb684448dea1d9871b2c07b122","IPY_MODEL_89b192a1616848dca6d6d6db6b4b5ed2"],"layout":"IPY_MODEL_6cae22165e4b476bb9f58672c4e25d48"}},"1d8f29410044465182058cb91da32b46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a513288d3ea74824bc7b76d547794412","placeholder":"‚Äã","style":"IPY_MODEL_1d8987304a504fe9957bae615448c3f2","value":"‚Äá‚Äá0%"}},"da665aeb684448dea1d9871b2c07b122":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61741a2f7d44210b11e8ddb66739647","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_067ce7d340d944dbbaacd67ac1e97e01","value":0}},"89b192a1616848dca6d6d6db6b4b5ed2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6199ef4d0db6419ab724cbfd763dafdd","placeholder":"‚Äã","style":"IPY_MODEL_f48ab74a01e14db19aa56e342f86b1fb","value":"‚Äá0/100‚Äá[00:00&lt;?,‚Äá?it/s]"}},"6cae22165e4b476bb9f58672c4e25d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a513288d3ea74824bc7b76d547794412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d8987304a504fe9957bae615448c3f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61741a2f7d44210b11e8ddb66739647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"067ce7d340d944dbbaacd67ac1e97e01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6199ef4d0db6419ab724cbfd763dafdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f48ab74a01e14db19aa56e342f86b1fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ebe854203cb4f83b1d870fb22c03a3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51faeea2ef844bc286524a343093da23","IPY_MODEL_4854ce0d8239441fbf74bdfffc67ed73","IPY_MODEL_61ada69697d6497cb2131f8d10440dc5"],"layout":"IPY_MODEL_db092b533db44a68be3342e41944c5ef"}},"51faeea2ef844bc286524a343093da23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b468cba634d406192607b8dada95326","placeholder":"‚Äã","style":"IPY_MODEL_542ccd9fa9094d27a85b33b6512fe4ed","value":"Training:‚Äá‚Äá‚Äá0%"}},"4854ce0d8239441fbf74bdfffc67ed73":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_71c4796a91cd4c539874f8fe97795d00","max":296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb96a16d926d45789998c100b498c0cc","value":0}},"61ada69697d6497cb2131f8d10440dc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_745bc55e3174424d95f43c571cf054f6","placeholder":"‚Äã","style":"IPY_MODEL_96e931cedca64f3ebe35126b0cde04b6","value":"‚Äá0/296‚Äá[00:00&lt;?,‚Äá?it/s]"}},"db092b533db44a68be3342e41944c5ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b468cba634d406192607b8dada95326":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"542ccd9fa9094d27a85b33b6512fe4ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71c4796a91cd4c539874f8fe97795d00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb96a16d926d45789998c100b498c0cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"745bc55e3174424d95f43c571cf054f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e931cedca64f3ebe35126b0cde04b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# üåüInitializing Phase\n","\n","In this section, we initialize the hyper parameters and load the training data"],"metadata":{"id":"Y_pXo7msWWRH"}},{"cell_type":"markdown","source":["### Seed Control"],"metadata":{"id":"nBJPo-dVaxB8"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","import torch\n","\n","SEED = 9999\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","print(\"Random sample (Python):\", random.random())\n","print(\"Random sample (NumPy):\", np.random.rand())\n","print(\"Random sample (PyTorch):\", torch.rand(1).item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwAIwb0EWLZI","executionInfo":{"status":"ok","timestamp":1764411223940,"user_tz":-480,"elapsed":31,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"outputId":"1c1cead1-141c-4e95-a2b1-dbd09086720d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random sample (Python): 0.8347577610922152\n","Random sample (NumPy): 0.8233890742543671\n","Random sample (PyTorch): 0.7876027822494507\n"]}]},{"cell_type":"markdown","source":["### Set Hyper Parameters\n","\n"],"metadata":{"id":"iMRQhVfKbDV3"}},{"cell_type":"code","source":["# According to the paper\n","EPOCHS = 100\n","BATCH_SIZE = 128\n","LEARNING_RATE = 0.1\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-4\n","LR_MILESTONES = [30, 60, 90]  # decayed by every 30 epochs\n","LR_GAMMA = 0.1  # \"decayed by 0.1\" (multiply lr by 0.1)"],"metadata":{"id":"nGoYz1HUbHWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Food-101 Data"],"metadata":{"id":"XD9ICeuOa1kS"}},{"cell_type":"code","source":["import os\n","import json\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","# =======================================================\n","# ÊéßÂà∂ÊòØÂê¶Âº∑Âà∂ÈáçÁÆó\n","# =======================================================\n","USE_PRECOMPUTED_STATS = True\n","STATS_FILE = \"food101_stats.json\"\n","\n","# =======================================================\n","# 1. Ë®àÁÆó food-101 mean & std ÔºåÂ¶ÇÊûúÂ∑≤Êúâ stats.json Áõ¥Êé•ËÆÄÂèñ\n","# =======================================================\n","\n","if USE_PRECOMPUTED_STATS and os.path.exists(STATS_FILE):\n","    print(f\"[INFO] Loading precomputed stats from {STATS_FILE} ...\")\n","\n","    with open(STATS_FILE, \"r\") as f:\n","        stats = json.load(f)\n","\n","    food101_mean = stats[\"mean\"]\n","    food101_std = stats[\"std\"]\n","\n","    print(\"Loaded mean:\", food101_mean)\n","    print(\"Loaded std :\", food101_std)\n","\n","else:\n","    print(\"[INFO] Computing mean/std for Food-101 (this may take a while)...\")\n","\n","    stats_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","    ])\n","\n","    food101_train_for_stats = datasets.Food101(\n","        root='./data',\n","        split='train',\n","        download=True,\n","        transform=stats_transform,\n","    )\n","\n","    # batch_size=1 ÈÅøÂÖç Collate Error\n","    stats_loader = data.DataLoader(\n","        food101_train_for_stats,\n","        batch_size=1,\n","        shuffle=False,\n","        num_workers=0,\n","    )\n","\n","    def compute_mean_std(loader):\n","        channel_sum = torch.zeros(3)\n","        channel_sq_sum = torch.zeros(3)\n","        total_pixels = 0\n","\n","        for imgs, _ in loader:\n","            imgs = imgs.squeeze(0)   # [C, H, W]\n","            c, h, w = imgs.shape\n","            pixels = h * w\n","\n","            channel_sum += imgs.sum(dim=[1, 2])\n","            channel_sq_sum += (imgs ** 2).sum(dim=[1, 2])\n","            total_pixels += pixels\n","\n","        mean = channel_sum / total_pixels\n","        std = torch.sqrt(channel_sq_sum / total_pixels - mean**2)\n","        return mean, std\n","\n","    food101_mean, food101_std = compute_mean_std(stats_loader)\n","\n","    food101_mean = food101_mean.tolist()\n","    food101_std = food101_std.tolist()\n","\n","    print(\"Computed mean:\", food101_mean)\n","    print(\"Computed std :\", food101_std)\n","\n","    # =======================================================\n","    # Â≠òÊàê JSONÔºå‰πãÂæåÂ∞±‰∏çÁî®ÂÜçË∑ë‰∫Ü\n","    # =======================================================\n","    stats = {\n","        \"mean\": food101_mean,\n","        \"std\": food101_std\n","    }\n","\n","    with open(STATS_FILE, \"w\") as f:\n","        json.dump(stats, f, indent=2)\n","\n","    print(f\"[INFO] Saved mean/std to {STATS_FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdZNVXqO7jsZ","executionInfo":{"status":"ok","timestamp":1764411882839,"user_tz":-480,"elapsed":657467,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"outputId":"24ed6ceb-3b6d-47b0-f4dd-e639d977b82d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Computing mean/std for Food-101 (this may take a while)...\n","Computed mean: [0.5493053793907166, 0.4449942111968994, 0.3435044288635254]\n","Computed std : [0.272877037525177, 0.2758291959762573, 0.2797982096672058]\n","[INFO] Saved mean/std to food101_stats.json\n"]}]},{"cell_type":"code","source":["# =======================================================\n","# 2. Official training transforms (ImageNet-style augmentation)\n","# =======================================================\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=food101_mean, std=food101_std),\n","])\n","\n","valid_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=food101_mean, std=food101_std),\n","])\n","\n","# =======================================================\n","# 3. Load Food-101 dataset\n","# =======================================================\n","\n","trainset = datasets.Food101(\n","    root='./data',\n","    split='train',\n","    download=False,\n","    transform=train_transform,\n",")\n","\n","testset = datasets.Food101(\n","    root='./data',\n","    split='test',\n","    download=False,\n","    transform=valid_transform,\n",")\n","\n","train_iterator = data.DataLoader(\n","    trainset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=8,\n","    pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","test_iterator = data.DataLoader(\n","    testset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=8,\n","    pin_memory=True,\n","    persistent_workers=True\n",")\n","\n","# =======================================================\n","# 4. Sanity check\n","# =======================================================\n","\n","images, labels = next(iter(train_iterator))\n","print(f\"Train samples: {len(trainset)}\")\n","print(f\"Test samples:  {len(testset)}\")\n","print(f\"Batch images shape: {images.shape}\")\n","print(f\"Batch labels shape: {labels.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RMJVlXi7eVy","executionInfo":{"status":"ok","timestamp":1764411889591,"user_tz":-480,"elapsed":6738,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"outputId":"d12b9d7c-9e6c-4c8e-e8de-9ca7955bc20e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 75750\n","Test samples:  25250\n","Batch images shape: torch.Size([256, 3, 224, 224])\n","Batch labels shape: torch.Size([256])\n"]}]},{"cell_type":"markdown","source":["# üåüModel Define\n","\n","In this section, we define our PyTorch model! After this section there will be a model named `resnet50_fresh` to train"],"metadata":{"id":"UeddHPIgjqOS"}},{"cell_type":"markdown","source":["### Basic model definition"],"metadata":{"id":"cfbvkbfilwMl"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","resnet50_fresh = models.resnet50(weights=None)  # load from scratch\n","resnet50_fresh.fc = nn.Linear(resnet50_fresh.fc.in_features, 101)  # for Food-101\n","resnet50_fresh = resnet50_fresh.to(device)\n","\n","print(\"Using device:\", device)"],"metadata":{"collapsed":true,"id":"iaRS5BL0j2O8","executionInfo":{"status":"ok","timestamp":1764411889993,"user_tz":-480,"elapsed":397,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f52ae32f-0e09-4935-8823-5f5872e8e129"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}]},{"cell_type":"markdown","source":["### More settings"],"metadata":{"id":"kUqmNKywl7PM"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(\n","    resnet50_fresh.parameters(),\n","    lr=LEARNING_RATE,\n","    momentum=MOMENTUM,\n","    weight_decay=WEIGHT_DECAY\n",")\n","\n","scheduler = optim.lr_scheduler.MultiStepLR(\n","    optimizer,\n","    milestones=LR_MILESTONES,\n","    gamma=LR_GAMMA\n",")\n","\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"0stin2q0mQYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Metrices (FLOPS, Params...)"],"metadata":{"id":"lKTDOm6Qg0u-"}},{"cell_type":"code","source":["from torchsummary import summary\n","\n","# Straightly simulate with the input data to see Params count\n","summary(resnet50_fresh, (3,224,224))"],"metadata":{"collapsed":true,"id":"GVvp1EUX8TxO","executionInfo":{"status":"ok","timestamp":1764411890820,"user_tz":-480,"elapsed":815,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"97700c2e-4c87-42ab-90ae-f9eb088f330f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","            Conv2d-5           [-1, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [-1, 64, 56, 56]             128\n","              ReLU-7           [-1, 64, 56, 56]               0\n","            Conv2d-8           [-1, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [-1, 64, 56, 56]             128\n","             ReLU-10           [-1, 64, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [-1, 256, 56, 56]             512\n","           Conv2d-13          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [-1, 256, 56, 56]             512\n","             ReLU-15          [-1, 256, 56, 56]               0\n","       Bottleneck-16          [-1, 256, 56, 56]               0\n","           Conv2d-17           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [-1, 64, 56, 56]             128\n","             ReLU-19           [-1, 64, 56, 56]               0\n","           Conv2d-20           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [-1, 64, 56, 56]             128\n","             ReLU-22           [-1, 64, 56, 56]               0\n","           Conv2d-23          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [-1, 256, 56, 56]             512\n","             ReLU-25          [-1, 256, 56, 56]               0\n","       Bottleneck-26          [-1, 256, 56, 56]               0\n","           Conv2d-27           [-1, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [-1, 64, 56, 56]             128\n","             ReLU-29           [-1, 64, 56, 56]               0\n","           Conv2d-30           [-1, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [-1, 64, 56, 56]             128\n","             ReLU-32           [-1, 64, 56, 56]               0\n","           Conv2d-33          [-1, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [-1, 256, 56, 56]             512\n","             ReLU-35          [-1, 256, 56, 56]               0\n","       Bottleneck-36          [-1, 256, 56, 56]               0\n","           Conv2d-37          [-1, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [-1, 128, 56, 56]             256\n","             ReLU-39          [-1, 128, 56, 56]               0\n","           Conv2d-40          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [-1, 128, 28, 28]             256\n","             ReLU-42          [-1, 128, 28, 28]               0\n","           Conv2d-43          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n","           Conv2d-45          [-1, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n","             ReLU-47          [-1, 512, 28, 28]               0\n","       Bottleneck-48          [-1, 512, 28, 28]               0\n","           Conv2d-49          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [-1, 128, 28, 28]             256\n","             ReLU-51          [-1, 128, 28, 28]               0\n","           Conv2d-52          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [-1, 128, 28, 28]             256\n","             ReLU-54          [-1, 128, 28, 28]               0\n","           Conv2d-55          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n","             ReLU-57          [-1, 512, 28, 28]               0\n","       Bottleneck-58          [-1, 512, 28, 28]               0\n","           Conv2d-59          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [-1, 128, 28, 28]             256\n","             ReLU-61          [-1, 128, 28, 28]               0\n","           Conv2d-62          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [-1, 128, 28, 28]             256\n","             ReLU-64          [-1, 128, 28, 28]               0\n","           Conv2d-65          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n","             ReLU-67          [-1, 512, 28, 28]               0\n","       Bottleneck-68          [-1, 512, 28, 28]               0\n","           Conv2d-69          [-1, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [-1, 128, 28, 28]             256\n","             ReLU-71          [-1, 128, 28, 28]               0\n","           Conv2d-72          [-1, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [-1, 128, 28, 28]             256\n","             ReLU-74          [-1, 128, 28, 28]               0\n","           Conv2d-75          [-1, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n","             ReLU-77          [-1, 512, 28, 28]               0\n","       Bottleneck-78          [-1, 512, 28, 28]               0\n","           Conv2d-79          [-1, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [-1, 256, 28, 28]             512\n","             ReLU-81          [-1, 256, 28, 28]               0\n","           Conv2d-82          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [-1, 256, 14, 14]             512\n","             ReLU-84          [-1, 256, 14, 14]               0\n","           Conv2d-85         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n","           Conv2d-87         [-1, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n","             ReLU-89         [-1, 1024, 14, 14]               0\n","       Bottleneck-90         [-1, 1024, 14, 14]               0\n","           Conv2d-91          [-1, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [-1, 256, 14, 14]             512\n","             ReLU-93          [-1, 256, 14, 14]               0\n","           Conv2d-94          [-1, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [-1, 256, 14, 14]             512\n","             ReLU-96          [-1, 256, 14, 14]               0\n","           Conv2d-97         [-1, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n","             ReLU-99         [-1, 1024, 14, 14]               0\n","      Bottleneck-100         [-1, 1024, 14, 14]               0\n","          Conv2d-101          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [-1, 256, 14, 14]             512\n","            ReLU-103          [-1, 256, 14, 14]               0\n","          Conv2d-104          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [-1, 256, 14, 14]             512\n","            ReLU-106          [-1, 256, 14, 14]               0\n","          Conv2d-107         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n","            ReLU-109         [-1, 1024, 14, 14]               0\n","      Bottleneck-110         [-1, 1024, 14, 14]               0\n","          Conv2d-111          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [-1, 256, 14, 14]             512\n","            ReLU-113          [-1, 256, 14, 14]               0\n","          Conv2d-114          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [-1, 256, 14, 14]             512\n","            ReLU-116          [-1, 256, 14, 14]               0\n","          Conv2d-117         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n","            ReLU-119         [-1, 1024, 14, 14]               0\n","      Bottleneck-120         [-1, 1024, 14, 14]               0\n","          Conv2d-121          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [-1, 256, 14, 14]             512\n","            ReLU-123          [-1, 256, 14, 14]               0\n","          Conv2d-124          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [-1, 256, 14, 14]             512\n","            ReLU-126          [-1, 256, 14, 14]               0\n","          Conv2d-127         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n","            ReLU-129         [-1, 1024, 14, 14]               0\n","      Bottleneck-130         [-1, 1024, 14, 14]               0\n","          Conv2d-131          [-1, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [-1, 256, 14, 14]             512\n","            ReLU-133          [-1, 256, 14, 14]               0\n","          Conv2d-134          [-1, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [-1, 256, 14, 14]             512\n","            ReLU-136          [-1, 256, 14, 14]               0\n","          Conv2d-137         [-1, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n","            ReLU-139         [-1, 1024, 14, 14]               0\n","      Bottleneck-140         [-1, 1024, 14, 14]               0\n","          Conv2d-141          [-1, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n","            ReLU-143          [-1, 512, 14, 14]               0\n","          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n","            ReLU-146            [-1, 512, 7, 7]               0\n","          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n","          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n","            ReLU-151           [-1, 2048, 7, 7]               0\n","      Bottleneck-152           [-1, 2048, 7, 7]               0\n","          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n","            ReLU-155            [-1, 512, 7, 7]               0\n","          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n","            ReLU-158            [-1, 512, 7, 7]               0\n","          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n","            ReLU-161           [-1, 2048, 7, 7]               0\n","      Bottleneck-162           [-1, 2048, 7, 7]               0\n","          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n","            ReLU-165            [-1, 512, 7, 7]               0\n","          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n","            ReLU-168            [-1, 512, 7, 7]               0\n","          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n","            ReLU-171           [-1, 2048, 7, 7]               0\n","      Bottleneck-172           [-1, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n","          Linear-174                  [-1, 101]         206,949\n","================================================================\n","Total params: 23,714,981\n","Trainable params: 23,714,981\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 286.55\n","Params size (MB): 90.47\n","Estimated Total Size (MB): 377.59\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# model structure\n","print(resnet50_fresh)"],"metadata":{"id":"DUQDPvxO8Wc0","executionInfo":{"status":"ok","timestamp":1764411890850,"user_tz":-480,"elapsed":26,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cd4aec82-4874-4882-d9c7-0f4ead101d62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=101, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["!pip install thop"],"metadata":{"id":"7-C2p7Nbg6hb","executionInfo":{"status":"ok","timestamp":1764411901742,"user_tz":-480,"elapsed":10889,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa2766f8-c6e5-4e1c-8a5f-eae890d4083f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.9.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n","Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["# FLOPS\n","def evaluate_model_complexity(model, input_size=(1, 3, 224, 224), device='cuda'):\n","    \"\"\"\n","    Ë©ï‰º∞Ê®°ÂûãÁöÑÂèÉÊï∏ÈáèËàáË®àÁÆóÈáè (FLOPs)„ÄÇ\n","    ÈúÄÂÆâË£ù thop: pip install thop\n","    \"\"\"\n","    try:\n","        from thop import profile, clever_format\n","    except ImportError:\n","        print(\"Error: 'thop' library is not installed. Please run: pip install thop\")\n","        return\n","\n","    model = model.to(device)\n","    model.eval()\n","\n","    dummy_input = torch.randn(input_size).to(device)\n","\n","    # Ë®àÁÆó FLOPs Âíå Params\n","    flops, params = profile(model, inputs=(dummy_input, ), verbose=False)\n","\n","    # Ê†ºÂºèÂåñËº∏Âá∫\n","    flops_fmt, params_fmt = clever_format([flops, params], \"%.3f\")\n","\n","    print(\"=\"*40)\n","    print(f\"FLOPs Evaluation\")\n","    print(f\"Input Shape: {input_size}\")\n","    print(f\"FLOPs: {flops_fmt}\")\n","    print(\"=\"*40)\n","\n","    return flops, params\n","\n","evaluate_model_complexity(resnet50_fresh, input_size=(1, 3, 224, 224), device=device)"],"metadata":{"id":"3GJU1tO7g0hY","executionInfo":{"status":"ok","timestamp":1764411902216,"user_tz":-480,"elapsed":468,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d82640a2-f0c0-4b15-c564-e9068d807e38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["========================================\n","FLOPs Evaluation\n","Input Shape: (1, 3, 224, 224)\n","FLOPs: 4.132G\n","========================================\n"]},{"output_type":"execute_result","data":{"text/plain":["(4131901440.0, 23714981.0)"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# üåüStart Training!"],"metadata":{"id":"hkYP6CeVnUQn"}},{"cell_type":"markdown","source":["### Define functions for training / evaluating w.r.t 1 epoch"],"metadata":{"id":"0VuTcd7lj4Op"}},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","\n","# Getting Acc in a batch\n","def calculate_accuracy(y_pred, y):\n","    top_pred = y_pred.argmax(1, keepdim=True)\n","    correct = top_pred.eq(y.view_as(top_pred)).sum()\n","    acc = correct.float() / y.shape[0]\n","    return acc\n","\n","# Train an epoch\n","def train(model, iterator, optimizer, criterion, device):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        # Reset gradients from the previous iteration (avoid accumulation)\n","        optimizer.zero_grad()\n","\n","        # Forward pass: compute logits/predictions for this batch\n","        y_pred = model(x)\n","        # Compute scalar loss for this batch (e.g., CrossEntropy)\n","        loss = criterion(y_pred, y)\n","        # Compute a metric for monitoring (e.g., top-1 accuracy)\n","        acc = calculate_accuracy(y_pred, y)\n","        # Backward pass: compute gradients w.r.t. all learnable parameters\n","        loss.backward()\n","\n","        # Optimizer step: update parameters using computed gradients\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","# Evaluate an epoch\n","def evaluate(model, iterator, criterion, device):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n","\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            y_pred = model(x)\n","\n","            loss = criterion(y_pred, y)\n","\n","            acc = calculate_accuracy(y_pred, y)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"DehQzajOh3cw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define the main training function"],"metadata":{"id":"bIwrPVCXl5Lq"}},{"cell_type":"code","source":["import time\n","\n","def train_model(model, train_iterator, test_iterator, device,\n","                optimizer, scheduler, criterion,\n","                epochs=EPOCHS, model_path='Best-ResNet50-Food101.pt'):\n","\n","    model = model.to(device)\n","\n","    optimizer = optimizer\n","    scheduler = scheduler\n","    criterion = criterion\n","\n","    best_valid_loss = float('inf')\n","\n","    train_losses = []\n","    train_accuracies = []\n","    valid_losses = []\n","    valid_accuracies = []\n","    learning_rates = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        start_time = time.monotonic()\n","\n","        train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n","        valid_loss, valid_acc = evaluate(model, test_iterator, criterion, device)\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), model_path)\n","\n","        end_time = time.monotonic()\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        # Decaying after an Epoch\n","        scheduler.step()\n","\n","        print(f'Epoch: {epoch+1} | Epoch Time: {epoch_mins}m {epoch_secs}s | LR: {current_lr:.5f}')\n","        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_acc)\n","        valid_losses.append(valid_loss)\n","        valid_accuracies.append(valid_acc)\n","        learning_rates.append(current_lr)\n","\n","    return {\n","        'train_losses': train_losses,\n","        'train_accuracies': train_accuracies,\n","        'valid_losses': valid_losses,\n","        'valid_accuracies': valid_accuracies,\n","        'learning_rates': learning_rates,\n","        'best_model_path': model_path\n","    }"],"metadata":{"id":"a02tNReSl8af"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Begins!!!!!"],"metadata":{"id":"NunxHy2fnOTO"}},{"cell_type":"code","source":["trained_model = resnet50_fresh.to(device)\n","\n","# call the train method\n","trained_stats = train_model(\n","    model=trained_model,\n","    train_iterator=train_iterator,\n","    test_iterator=test_iterator,\n","    device=device,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n","    criterion=criterion,\n",")\n","\n","torch.save(trained_stats, 'trained_stats_ResNet50_Food101.pt')"],"metadata":{"id":"3i_6Lfb2nSJh","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["3a467aa071e54d858887a056c44379c3","1d8f29410044465182058cb91da32b46","da665aeb684448dea1d9871b2c07b122","89b192a1616848dca6d6d6db6b4b5ed2","6cae22165e4b476bb9f58672c4e25d48","a513288d3ea74824bc7b76d547794412","1d8987304a504fe9957bae615448c3f2","b61741a2f7d44210b11e8ddb66739647","067ce7d340d944dbbaacd67ac1e97e01","6199ef4d0db6419ab724cbfd763dafdd","f48ab74a01e14db19aa56e342f86b1fb","9ebe854203cb4f83b1d870fb22c03a3e","51faeea2ef844bc286524a343093da23","4854ce0d8239441fbf74bdfffc67ed73","61ada69697d6497cb2131f8d10440dc5","db092b533db44a68be3342e41944c5ef","4b468cba634d406192607b8dada95326","542ccd9fa9094d27a85b33b6512fe4ed","71c4796a91cd4c539874f8fe97795d00","eb96a16d926d45789998c100b498c0cc","745bc55e3174424d95f43c571cf054f6","96e931cedca64f3ebe35126b0cde04b6"]},"outputId":"4c5e75e7-8fa1-4a9e-84bc-56dbde29665a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a467aa071e54d858887a056c44379c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Training:   0%|          | 0/296 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ebe854203cb4f83b1d870fb22c03a3e"}},"metadata":{}}]},{"cell_type":"markdown","source":["# üåüEvaluation Time"],"metadata":{"id":"KUDMdtRKqrK5"}},{"cell_type":"code","source":["# # Reload the model (Optional)\n","# trained_model = resnet50_fresh\n","# trained_model.load_state_dict(torch.load('Best-ResNet50-Food101.pt'))\n","\n","# trained_stats = torch.load('trained_stats_ResNet50_Food101.pt', map_location=device)"],"metadata":{"id":"Qz5nifheflPF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The Loss and Accuracy Curve"],"metadata":{"id":"zwiXbpvCquFh"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_and_accuracy(trained_stats):\n","    epochs_to_show = EPOCHS\n","    epochs = range(1, epochs_to_show + 1)\n","\n","    # Plot Loss\n","    plt.figure(figsize=(10, 4))\n","    plt.plot(epochs, trained_stats[\"train_losses\"][:epochs_to_show], label='Train Loss')\n","    plt.plot(epochs, trained_stats[\"valid_losses\"][:epochs_to_show], label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    # Plot Accuracy\n","    plt.figure(figsize=(10, 4))\n","    plt.plot(epochs, [acc * 100 for acc in trained_stats[\"train_accuracies\"][:epochs_to_show]], label='Train Accuracy')\n","    plt.plot(epochs, [acc * 100 for acc in trained_stats[\"valid_accuracies\"][:epochs_to_show]], label='Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.title('Training and Validation Accuracy')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","plot_loss_and_accuracy(trained_stats)"],"metadata":{"id":"C4hglqwPqxTR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The Most Incorrect"],"metadata":{"id":"u7P3kPtmUmA8"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import heapq\n","\n","def plot_most_incorrect(trained_model, test_iterator, device, n_images=16, class_names=None):\n","    trained_model.eval()\n","\n","    # Use a min-heap to keep only top N incorrect examples\n","    # Format: (confidence, index, image, true_label, probs)\n","    # We use negative confidence for max-heap behavior\n","    incorrect_heap = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (x, y) in enumerate(test_iterator):\n","            x = x.to(device)\n","            y_pred = trained_model(x)\n","            y_prob = F.softmax(y_pred, dim=-1)\n","\n","            # Move to CPU immediately and process\n","            y_prob_cpu = y_prob.cpu()\n","            y_cpu = y.cpu()\n","            x_cpu = x.cpu()\n","\n","            pred_labels = torch.argmax(y_prob_cpu, 1)\n","\n","            # Process each image in the batch\n","            for i in range(x_cpu.size(0)):\n","                if pred_labels[i] != y_cpu[i]:\n","                    # Get the confidence of incorrect prediction\n","                    incorrect_prob = y_prob_cpu[i, pred_labels[i]].item()\n","\n","                    # Use negative for max-heap behavior with heapq (min-heap)\n","                    item = (-incorrect_prob, batch_idx * len(x) + i,\n","                           x_cpu[i].clone(), y_cpu[i].item(), y_prob_cpu[i].clone())\n","\n","                    if len(incorrect_heap) < n_images:\n","                        heapq.heappush(incorrect_heap, item)\n","                    elif -incorrect_prob > incorrect_heap[0][0]:\n","                        heapq.heapreplace(incorrect_heap, item)\n","\n","            # Clear batch from memory\n","            del x, y_pred, y_prob, y_prob_cpu, y_cpu, x_cpu\n","\n","    # Sort by confidence (descending)\n","    incorrect_examples = sorted(incorrect_heap, key=lambda x: x[0])\n","\n","    # Plot results\n","    rows = int(np.sqrt(n_images))\n","    cols = int(np.ceil(n_images / rows))\n","\n","    fig = plt.figure(figsize=(cols * 1.5, rows * 1.5))\n","    for i in range(min(len(incorrect_examples), rows * cols)):\n","        ax = fig.add_subplot(rows, cols, i + 1)\n","\n","        _, _, image, true_label, probs = incorrect_examples[i]\n","        true_prob = probs[true_label].item()\n","        incorrect_prob, incorrect_label = torch.max(probs, dim=0)\n","        incorrect_prob = incorrect_prob.item()\n","        incorrect_label = incorrect_label.item()\n","\n","        # Prepare image for display\n","        img = image.permute(1, 2, 0).numpy()\n","        img = np.clip(img, 0, 1)\n","        ax.imshow(img)\n","\n","        # Set title\n","        if class_names:\n","            title = f'True: {class_names[true_label]} ({true_prob:.2f})\\nPred: {class_names[incorrect_label]} ({incorrect_prob:.2f})'\n","        else:\n","            title = f'True: {true_label} ({true_prob:.2f})\\nPred: {incorrect_label} ({incorrect_prob:.2f})'\n","\n","        ax.set_title(title, fontsize=9)\n","        ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_most_incorrect(trained_model, test_iterator, device, 16, class_names=trainset.classes)"],"metadata":{"id":"xqcccLoqlDTj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The final loss and accuracy"],"metadata":{"id":"FxBwuYNDXulg"}},{"cell_type":"code","source":["test_loss, test_acc = evaluate(trained_model, test_iterator, criterion, device)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"metadata":{"id":"0CykoQf1YG0a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Display Feature Maps (TODO)"],"metadata":{"id":"st8qH1wzYzNT"}},{"cell_type":"code","source":[],"metadata":{"id":"WRXObq2DZnY2"},"execution_count":null,"outputs":[]}]}