{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üåüInitializing Phase\n","\n","In this section, we initialize the hyper parameters and load the training data"],"metadata":{"id":"Y_pXo7msWWRH"}},{"cell_type":"markdown","source":["### Seed Control"],"metadata":{"id":"nBJPo-dVaxB8"}},{"cell_type":"code","source":["import random\n","import numpy as np\n","import torch\n","\n","SEED = 9999\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","print(\"Random sample (Python):\", random.random())\n","print(\"Random sample (NumPy):\", np.random.rand())\n","print(\"Random sample (PyTorch):\", torch.rand(1).item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwAIwb0EWLZI","executionInfo":{"status":"ok","timestamp":1764385854838,"user_tz":-480,"elapsed":12118,"user":{"displayName":"ÊûóÂ≠êÈΩä","userId":"16169248093131835592"}},"outputId":"eb090686-927a-417b-bc56-98ee1c6578b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random sample (Python): 0.8347577610922152\n","Random sample (NumPy): 0.8233890742543671\n","Random sample (PyTorch): 0.7876027822494507\n"]}]},{"cell_type":"markdown","source":["### Set Hyper Parameters\n","\n"],"metadata":{"id":"iMRQhVfKbDV3"}},{"cell_type":"code","source":["# According to the paper\n","EPOCHS = 100\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.1\n","MOMENTUM = 0.9\n","WEIGHT_DECAY = 1e-4\n","LR_MILESTONES = [30, 60, 90]  # decayed by every 30 epochs\n","LR_GAMMA = 0.1  # \"decayed by 0.1\" (multiply lr by 0.1)"],"metadata":{"id":"nGoYz1HUbHWR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load Food-101"],"metadata":{"id":"XD9ICeuOa1kS"}},{"cell_type":"code","source":["import os\n","import json\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","# =======================================================\n","# ÊéßÂà∂ÊòØÂê¶Âº∑Âà∂ÈáçÁÆó\n","# =======================================================\n","USE_PRECOMPUTED_STATS = True\n","STATS_FILE = \"food101_stats.json\"\n","\n","# =======================================================\n","# 1. Ë®àÁÆó food-101 mean & std ÔºåÂ¶ÇÊûúÂ∑≤Êúâ stats.json Áõ¥Êé•ËÆÄÂèñ\n","# =======================================================\n","\n","if USE_PRECOMPUTED_STATS and os.path.exists(STATS_FILE):\n","    print(f\"[INFO] Loading precomputed stats from {STATS_FILE} ...\")\n","\n","    with open(STATS_FILE, \"r\") as f:\n","        stats = json.load(f)\n","\n","    food101_mean = stats[\"mean\"]\n","    food101_std = stats[\"std\"]\n","\n","    print(\"Loaded mean:\", food101_mean)\n","    print(\"Loaded std :\", food101_std)\n","\n","else:\n","    print(\"[INFO] Computing mean/std for Food-101 (this may take a while)...\")\n","\n","    stats_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","    ])\n","\n","    food101_train_for_stats = datasets.Food101(\n","        root='./data',\n","        split='train',\n","        download=True,\n","        transform=stats_transform,\n","    )\n","\n","    # batch_size=1 ÈÅøÂÖç Collate Error\n","    stats_loader = data.DataLoader(\n","        food101_train_for_stats,\n","        batch_size=1,\n","        shuffle=False,\n","        num_workers=0,\n","    )\n","\n","    def compute_mean_std(loader):\n","        channel_sum = torch.zeros(3)\n","        channel_sq_sum = torch.zeros(3)\n","        total_pixels = 0\n","\n","        for imgs, _ in loader:\n","            imgs = imgs.squeeze(0)   # [C, H, W]\n","            c, h, w = imgs.shape\n","            pixels = h * w\n","\n","            channel_sum += imgs.sum(dim=[1, 2])\n","            channel_sq_sum += (imgs ** 2).sum(dim=[1, 2])\n","            total_pixels += pixels\n","\n","        mean = channel_sum / total_pixels\n","        std = torch.sqrt(channel_sq_sum / total_pixels - mean**2)\n","        return mean, std\n","\n","    food101_mean, food101_std = compute_mean_std(stats_loader)\n","\n","    food101_mean = food101_mean.tolist()\n","    food101_std = food101_std.tolist()\n","\n","    print(\"Computed mean:\", food101_mean)\n","    print(\"Computed std :\", food101_std)\n","\n","    # =======================================================\n","    # Â≠òÊàê JSONÔºå‰πãÂæåÂ∞±‰∏çÁî®ÂÜçË∑ë‰∫Ü\n","    # =======================================================\n","    stats = {\n","        \"mean\": food101_mean,\n","        \"std\": food101_std\n","    }\n","\n","    with open(STATS_FILE, \"w\") as f:\n","        json.dump(stats, f, indent=2)\n","\n","    print(f\"[INFO] Saved mean/std to {STATS_FILE}\")"],"metadata":{"id":"uwnj7atOEgCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =======================================================\n","# 2. Official training transforms (ImageNet-style augmentation)\n","# =======================================================\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=food101_mean, std=food101_std),\n","])\n","\n","valid_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=food101_mean, std=food101_std),\n","])\n","\n","# =======================================================\n","# 3. Load Food-101 dataset\n","# =======================================================\n","\n","trainset = datasets.Food101(\n","    root='./data',\n","    split='train',\n","    download=False,\n","    transform=train_transform,\n",")\n","\n","testset = datasets.Food101(\n","    root='./data',\n","    split='test',\n","    download=False,\n","    transform=valid_transform,\n",")\n","\n","train_iterator = data.DataLoader(\n","    trainset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=4,\n",")\n","\n","test_iterator = data.DataLoader(\n","    testset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=4,\n",")\n","\n","# =======================================================\n","# 4. Sanity check\n","# =======================================================\n","\n","images, labels = next(iter(train_iterator))\n","print(f\"Train samples: {len(trainset)}\")\n","print(f\"Test samples:  {len(testset)}\")\n","print(f\"Batch images shape: {images.shape}\")\n","print(f\"Batch labels shape: {labels.shape}\")"],"metadata":{"id":"yhZ9y-OPEh8j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üåüModel Define\n","\n","In this section, we define our PyTorch model! After this section there will be a model named `densenet121_fresh` to train"],"metadata":{"id":"UeddHPIgjqOS"}},{"cell_type":"markdown","source":["### Basic model definition"],"metadata":{"id":"cfbvkbfilwMl"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","densenet121_fresh = models.densenet121(weights=None)  # load from scratch\n","densenet121_fresh.classifier = nn.Linear(densenet121_fresh.classifier.in_features, 101)  # for Food-101\n","densenet121_fresh = densenet121_fresh.to(device)\n","\n","print(\"Using device:\", device)"],"metadata":{"collapsed":true,"id":"iaRS5BL0j2O8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### More settings"],"metadata":{"id":"kUqmNKywl7PM"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(\n","    densenet121_fresh.parameters(),\n","    lr=LEARNING_RATE,\n","    momentum=MOMENTUM,\n","    weight_decay=WEIGHT_DECAY\n",")\n","\n","scheduler = optim.lr_scheduler.MultiStepLR(\n","    optimizer,\n","    milestones=LR_MILESTONES,\n","    gamma=LR_GAMMA\n",")\n","\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"0stin2q0mQYl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model Metrices (FLOPS, Params...)"],"metadata":{"id":"lKTDOm6Qg0u-"}},{"cell_type":"code","source":["!pip install torchinfo"],"metadata":{"id":"66oq8vOJDGGm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchinfo import summary\n","\n","# Straightly simulate with the input data to see Params count\n","summary(densenet121_fresh, (1, 3, 224, 224))"],"metadata":{"collapsed":true,"id":"GVvp1EUX8TxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model structure\n","print(densenet121_fresh)"],"metadata":{"id":"DUQDPvxO8Wc0","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install thop"],"metadata":{"id":"7-C2p7Nbg6hb","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FLOPS\n","def evaluate_model_complexity(model, input_size=(1, 3, 224, 224), device='cuda'):\n","    \"\"\"\n","    Ë©ï‰º∞Ê®°ÂûãÁöÑÂèÉÊï∏ÈáèËàáË®àÁÆóÈáè (FLOPs)„ÄÇ\n","    ÈúÄÂÆâË£ù thop: pip install thop\n","    \"\"\"\n","    try:\n","        from thop import profile, clever_format\n","    except ImportError:\n","        print(\"Error: 'thop' library is not installed. Please run: pip install thop\")\n","        return\n","\n","    model = model.to(device)\n","    model.eval()\n","\n","    dummy_input = torch.randn(input_size).to(device)\n","\n","    # Ë®àÁÆó FLOPs Âíå Params\n","    flops, params = profile(model, inputs=(dummy_input, ), verbose=False)\n","\n","    # Ê†ºÂºèÂåñËº∏Âá∫\n","    flops_fmt, params_fmt = clever_format([flops, params], \"%.3f\")\n","\n","    print(\"=\"*40)\n","    print(f\"FLOPs Evaluation\")\n","    print(f\"Input Shape: {input_size}\")\n","    print(f\"FLOPs: {flops_fmt}\")\n","    print(\"=\"*40)\n","\n","    return flops, params\n","\n","evaluate_model_complexity(densenet121_fresh, input_size=(1, 3, 224, 224), device=device)"],"metadata":{"id":"3GJU1tO7g0hY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üåüStart Training!"],"metadata":{"id":"hkYP6CeVnUQn"}},{"cell_type":"markdown","source":["### Define functions for training / evaluating w.r.t 1 epoch"],"metadata":{"id":"0VuTcd7lj4Op"}},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","\n","# Getting Acc in a batch\n","def calculate_accuracy(y_pred, y):\n","    top_pred = y_pred.argmax(1, keepdim=True)\n","    correct = top_pred.eq(y.view_as(top_pred)).sum()\n","    acc = correct.float() / y.shape[0]\n","    return acc\n","\n","# Train an epoch\n","def train(model, iterator, optimizer, criterion, device):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n","        x = x.to(device)\n","        y = y.to(device)\n","\n","        # Reset gradients from the previous iteration (avoid accumulation)\n","        optimizer.zero_grad()\n","\n","        # Forward pass: compute logits/predictions for this batch\n","        y_pred = model(x)\n","        # Compute scalar loss for this batch (e.g., CrossEntropy)\n","        loss = criterion(y_pred, y)\n","        # Compute a metric for monitoring (e.g., top-1 accuracy)\n","        acc = calculate_accuracy(y_pred, y)\n","        # Backward pass: compute gradients w.r.t. all learnable parameters\n","        loss.backward()\n","\n","        # Optimizer step: update parameters using computed gradients\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","# Evaluate an epoch\n","def evaluate(model, iterator, criterion, device):\n","\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","\n","        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n","\n","            x = x.to(device)\n","            y = y.to(device)\n","\n","            y_pred = model(x)\n","\n","            loss = criterion(y_pred, y)\n","\n","            acc = calculate_accuracy(y_pred, y)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"DehQzajOh3cw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Define the main training function"],"metadata":{"id":"bIwrPVCXl5Lq"}},{"cell_type":"code","source":["import time\n","\n","def train_model(model, train_iterator, test_iterator, device,\n","                optimizer, scheduler, criterion,\n","                epochs=EPOCHS, model_path='Best-DenseNet121-Food101.pt'):\n","\n","    model = model.to(device)\n","\n","    optimizer = optimizer\n","    scheduler = scheduler\n","    criterion = criterion\n","\n","    best_valid_loss = float('inf')\n","\n","    train_losses = []\n","    train_accuracies = []\n","    valid_losses = []\n","    valid_accuracies = []\n","    learning_rates = []\n","\n","    for epoch in tqdm(range(epochs)):\n","        start_time = time.monotonic()\n","\n","        train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n","        valid_loss, valid_acc = evaluate(model, test_iterator, criterion, device)\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), model_path)\n","\n","        end_time = time.monotonic()\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        # Decaying after an Epoch\n","        scheduler.step()\n","\n","        print(f'Epoch: {epoch+1} | Epoch Time: {epoch_mins}m {epoch_secs}s | LR: {current_lr:.5f}')\n","        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n","\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_acc)\n","        valid_losses.append(valid_loss)\n","        valid_accuracies.append(valid_acc)\n","        learning_rates.append(current_lr)\n","\n","    return {\n","        'train_losses': train_losses,\n","        'train_accuracies': train_accuracies,\n","        'valid_losses': valid_losses,\n","        'valid_accuracies': valid_accuracies,\n","        'learning_rates': learning_rates,\n","        'best_model_path': model_path\n","    }"],"metadata":{"id":"a02tNReSl8af"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Begins!!!!!"],"metadata":{"id":"NunxHy2fnOTO"}},{"cell_type":"code","source":["trained_model = densenet121_fresh.to(device)\n","\n","# call the train method\n","trained_stats = train_model(\n","    model=trained_model,\n","    train_iterator=train_iterator,\n","    test_iterator=test_iterator,\n","    device=device,\n","    optimizer=optimizer,\n","    scheduler=scheduler,\n","    criterion=criterion,\n",")\n","\n","torch.save(trained_stats, 'trained_stats_DenseNet121_Food101.pt')"],"metadata":{"id":"3i_6Lfb2nSJh","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üåüEvaluation Time"],"metadata":{"id":"KUDMdtRKqrK5"}},{"cell_type":"code","source":["# # Reload the model (Optional)\n","# trained_model = densenet121_fresh\n","# trained_model.load_state_dict(torch.load('Best-DenseNet121-Food101.pt'))\n","\n","# trained_stats = torch.load('trained_stats_DenseNet121_Food101.pt', map_location=device)"],"metadata":{"id":"Qz5nifheflPF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The Loss and Accuracy Curve"],"metadata":{"id":"zwiXbpvCquFh"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_and_accuracy(trained_stats):\n","    epochs_to_show = EPOCHS\n","    epochs = range(1, epochs_to_show + 1)\n","\n","    # Plot Loss\n","    plt.figure(figsize=(10, 4))\n","    plt.plot(epochs, trained_stats[\"train_losses\"][:epochs_to_show], label='Train Loss')\n","    plt.plot(epochs, trained_stats[\"valid_losses\"][:epochs_to_show], label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","    # Plot Accuracy\n","    plt.figure(figsize=(10, 4))\n","    plt.plot(epochs, [acc * 100 for acc in trained_stats[\"train_accuracies\"][:epochs_to_show]], label='Train Accuracy')\n","    plt.plot(epochs, [acc * 100 for acc in trained_stats[\"valid_accuracies\"][:epochs_to_show]], label='Validation Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.title('Training and Validation Accuracy')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","plot_loss_and_accuracy(trained_stats)"],"metadata":{"id":"C4hglqwPqxTR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The Most Incorrect"],"metadata":{"id":"u7P3kPtmUmA8"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import heapq\n","\n","def plot_most_incorrect(trained_model, test_iterator, device, n_images=16, class_names=None):\n","    trained_model.eval()\n","\n","    # Use a min-heap to keep only top N incorrect examples\n","    # Format: (confidence, index, image, true_label, probs)\n","    # We use negative confidence for max-heap behavior\n","    incorrect_heap = []\n","\n","    with torch.no_grad():\n","        for batch_idx, (x, y) in enumerate(test_iterator):\n","            x = x.to(device)\n","            y_pred = trained_model(x)\n","            y_prob = F.softmax(y_pred, dim=-1)\n","\n","            # Move to CPU immediately and process\n","            y_prob_cpu = y_prob.cpu()\n","            y_cpu = y.cpu()\n","            x_cpu = x.cpu()\n","\n","            pred_labels = torch.argmax(y_prob_cpu, 1)\n","\n","            # Process each image in the batch\n","            for i in range(x_cpu.size(0)):\n","                if pred_labels[i] != y_cpu[i]:\n","                    # Get the confidence of incorrect prediction\n","                    incorrect_prob = y_prob_cpu[i, pred_labels[i]].item()\n","\n","                    # Use negative for max-heap behavior with heapq (min-heap)\n","                    item = (-incorrect_prob, batch_idx * len(x) + i,\n","                           x_cpu[i].clone(), y_cpu[i].item(), y_prob_cpu[i].clone())\n","\n","                    if len(incorrect_heap) < n_images:\n","                        heapq.heappush(incorrect_heap, item)\n","                    elif -incorrect_prob > incorrect_heap[0][0]:\n","                        heapq.heapreplace(incorrect_heap, item)\n","\n","            # Clear batch from memory\n","            del x, y_pred, y_prob, y_prob_cpu, y_cpu, x_cpu\n","\n","    # Sort by confidence (descending)\n","    incorrect_examples = sorted(incorrect_heap, key=lambda x: x[0])\n","\n","    # Plot results\n","    rows = int(np.sqrt(n_images))\n","    cols = int(np.ceil(n_images / rows))\n","\n","    fig = plt.figure(figsize=(cols * 1.5, rows * 1.5))\n","    for i in range(min(len(incorrect_examples), rows * cols)):\n","        ax = fig.add_subplot(rows, cols, i + 1)\n","\n","        _, _, image, true_label, probs = incorrect_examples[i]\n","        true_prob = probs[true_label].item()\n","        incorrect_prob, incorrect_label = torch.max(probs, dim=0)\n","        incorrect_prob = incorrect_prob.item()\n","        incorrect_label = incorrect_label.item()\n","\n","        # Prepare image for display\n","        img = image.permute(1, 2, 0).numpy()\n","        img = np.clip(img, 0, 1)\n","        ax.imshow(img)\n","\n","        # Set title\n","        if class_names:\n","            title = f'True: {class_names[true_label]} ({true_prob:.2f})\\nPred: {class_names[incorrect_label]} ({incorrect_prob:.2f})'\n","        else:\n","            title = f'True: {true_label} ({true_prob:.2f})\\nPred: {incorrect_label} ({incorrect_prob:.2f})'\n","\n","        ax.set_title(title, fontsize=9)\n","        ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_most_incorrect(trained_model, test_iterator, device, 16, class_names=trainset.classes)"],"metadata":{"id":"xqcccLoqlDTj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### The final loss and accuracy"],"metadata":{"id":"FxBwuYNDXulg"}},{"cell_type":"code","source":["test_loss, test_acc = evaluate(trained_model, test_iterator, criterion, device)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"metadata":{"id":"0CykoQf1YG0a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Display Feature Maps (TODO)"],"metadata":{"id":"st8qH1wzYzNT"}},{"cell_type":"code","source":[],"metadata":{"id":"QRA9nUdBU1Wb"},"execution_count":null,"outputs":[]}]}